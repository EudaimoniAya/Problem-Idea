主流的向量数据库：milvus、pinecone、faiss、chroma、qdrant、weaviate
* milvus是一个开源的分布式向量数据库，复杂度中等偏高，性能优秀，查询延迟<50 ms。
  1) 分布式架构，支持水平扩展。
  2) 多种索引类型，如HNSW、IVF_FLAT等
  3) 混合查询（同时使用向量+标量过滤）
  4) GPU加速，亿级的向量处理
* pinecone是一个全托管服务的向量数据库，复杂度低，性能优秀，查询延迟< 100 ms。但是价格昂贵，$70/月起。
  1) 使用Serverless架构，自动扩/缩容
  2) 99.95%的SLA可用性
  3) 支持混合向量（稀疏+稠密）查询
  4) 简化的API，零运维负担
* faiss是一个向量检索库，并非一个完整的数据库，复杂度中等，性能极佳，专注于高维相似性搜索。
  1) 极致性能，专为相似性搜索优化
  2) 多种量化技术（PQ、SQ等），内存占用量小
  3) 支持GPU加上，处理速度快
  4) 轻量级库，易于集成
* chroma是一个轻量级开发使用的开源向量数据库，复杂度极低，但性能一般，向量规模达到百万级，适合小团队开发使用。
  1) 零配置安装，开箱即用
  2) 与AI工具链深度集成
  3) 轻量级设计，低资源消耗
  4) 支持混合查询（文本+向量）
* qdrant是一个开源高性能向量数据库，复杂度中低，性能优秀
  1) Rust开发，高性能与低内存占用
  2) 支持命名向量，单个数据点多个向量
  3) 强大的**地理位置过滤**功能
  4) 实时索引更新，毫秒级响应
* weaviate是一个开源的多模态向量数据库，复杂度中等，性能优秀
  1) GraphQL API，灵活的数据查询
  2) 原生支持多模态数据
  3) 内置嵌入模型，简化开发流程
  4) 支持知识图谱与向量搜索结合

场景化选型指南
* RAG应用：需要快速检索相关文档片段，支持元数据过滤，低延迟响应
  1) 推荐pinecone：全托管服务，低延迟，自动扩/缩容，适合快速上线
  2) 备选weaviate：内置多种嵌入模型，支持GraphQL，适合复杂RAG场景
  3) 备选milvus：开源分布式，适合大规模文档库和企业级部署
* 推荐系统：需要处理海量用户的行为向量，支持实时更新，高并发查询
  1) 推荐milvus：分布式架构，高性能，支持十亿级向量，适合大规模推荐系统
  2) 备选pinecone：低延迟，自动扩/缩容，适合快速迭代的推荐系统
  3) 备选qdrant：由Rust开发，高性能，支持地理位置过滤，适合本地部署的推荐系统
* 多模态检索：需要处理图像、文本、音频等多种模态数据，支持跨模态检索
  1) 推荐weaviate：原生支持多模态数据，内置多种嵌入模型，适合复杂多模态数据
  2) 备选milvus：支持多向量字段，可存储不同模态的向量表示，适合大规模多模态系统
  3) 备选pinecone：支持混合向量检索，易于使用，适合快速原型和中小规模多模态应用
* 原型开发与研究：需要易于安装和使用，快速迭代，低资源消耗
  1) 推荐chroma：零配置安装，与AI工具链深度集成，适合快速原型开发
  2) 推荐faiss：极致性能，多种索引算法，适合学术研究和算法验证
  3) 备选milvus lite：它是milvus的轻量级版本，适合开发环境和小规模数据场景

![[Snipaste_2026-01-15_08-56-07.png]]

选型建议：
* 新手/小型项目：数据量小，需求简单，快速验证想法，推荐chroma或faiss
* 中型应用：数据量中等，需要一定的性能和扩展性，推荐qdrant或weaviate
* 大型企业级应用：海量数据，高并发，复杂查询需求，推荐milvus或pinecone
另外，如果有特定需求，则需定向选择：
* 需要地理空间搜索：qdrant提供强大的地理位置过滤功能，适合基于位置的应用
* 多模态数据支持：weaviate原生支持多模态数据，内置多种嵌入模型
* GPU加速需求：milvus和faiss提供GPU加速，适合大规模向量处理
* 零运维成本：pinecone作为全托管服务，无需担心基础设施管理
* GraphQL查询支持：weaviate提供GraphQL API，适合复杂数据关系查询
* 多向量字段支持：qdrant支持命名向量，允许单个数据点包含多个向量