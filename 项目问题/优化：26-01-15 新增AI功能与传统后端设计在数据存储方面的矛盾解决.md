## 总结



## 学习过程
### 一、技术选型
根据B站的向量数据库测评总结以及AI分析得到的整理文档[[向量库技术对比]]，再结合初步打算实现的功能：**商品推荐和商品知识库**。考虑分别针对两个功能选择不同类型的向量数据库：
* 使用faiss+Redis存储**用户行为向量**；
* 使用PostgreSQL + pgvector实现**商品数据的向量保存**；
* 使用qdrant实现**知识库检索**。

> [!重要问题]
> **Q：** 在[[优化：26-01-07 模块解耦思想在仓储层中的应用]]和[[优化：26-01-08 二维架构设计思想解决AI功能的融入问题]]两篇记录中，我总结出来的数据/仓储层的设计是：
> * MySQL存储用户、商品、订单等信息；
> * PostgreSQL存储智能体上下文消息；
> * Redis存储高频的非关键信息
> * 向量数据库选择暂定
> * 并且把和AI相关的数据库：向量数据库和负责会话存储的PostgreSQL放入`core/ai/data`目录中
> 
> 但是上面的推荐技术选型中，”使用PostgreSQL + pgvector实现商品数据的保存“，与我目前的MySQL数据库存储商品实现了冲突。**我希望商品知识库的功能能够企业级规范地实践，但是目前的设计出现了同一数据库（PostgreSQL）将要分别实现水平领域和垂直领域功能的需求；并且从另一角度看，商品实体要同时实现传统后端事务处理（保持原样）和向量检索（改变数据库使用向量存储），应该如何协调以平衡这个矛盾，并且避免代码大量重复**？我的想法是使用单例依赖项分别注入到AI模块实现会话存取，以及后端仓储模块实现商品存取中，它们存取的数据类型不同，所以可能并没有多少代码重复。但是如果单是商品使用了PostgreSQL，又会不会让主应用的数据库不够同一，**需不需要把其他数据统一转移到PostgreSQL**？另外**如果是在已经部署的生产环境下，MySQL数据库已经存在大量的数据了**，即使完成了商品部分的转移以更好地实现RAG功能，**那对于其他字段的安排又有什么更专业的做法，是全部迁移还是仅迁移冲突数据**？
> 
> **A：** 这种冲突情况不推荐数据的全部迁移，甚至不推荐把冲突字段（商品）彻底迁移，因为MySQL在事务处理上非常成熟，全部迁移不合适，把冲突的几个表迁移也不太合适，因为那会导致传统后端业务的不方便。在生产环境下（已经存储了大量业务数据时），更成熟的做法是：**领域驱动设计（DDD）的限界上下文**【注：DDD的思想在[[优化：26-01-08 二维架构设计思想解决AI功能的融入问题]]中也有体现】，**即同一实体在不同上下文可以有不同的表示，一个商品实体可以在传统后端业务中有交易上下文（MySQL），在AI模块中有AI上下文（PostgreSQL + pgvector）**。
> 简单来说就是：**不迁移，而是保留MySQL的冲突数据（商品，将其作为权威数据源）**，让完整的事务数据还是由MySQL统一管控。但是对于冲突的解决，则是**另外开一个PostgreSQL + pgvector，作为实现冲突数据的”附加属性“，实现双存储。这就像是向量数据是MySQL冲突实体的一个向量形式的知识挂件（衍生数据视图）**。它只在AI需要的时候单独从PostgreSQL调用。此外，这两个需要同步，所以有一些策略保证在持续运行的情况下能异步地向PostgreSQL更新已存在的商品知识。
> **这种异构数据库架构的做法体现了数据网格的思想（把数据按职责划分给不同团队管控，让MySQL负责交易数据，让PostgreSQL负责向量知识存储），保证MySQL管钱、PostgreSQL+pgvector管知识、Redis管速度。**
> 结合这样的思想，将项目的`ai`模块的单个数据文件整合为为一个数据层模块：
> ```text
> │   └── ai/                   # AI核心（重构为清晰的层级）  
> │       ├── data/             # ⭐数据层（是智能化的数据基础设施层）  
> │       │   ├── models/          # 是AI功能需要的模型 
> │       │   │   ├── product_vector.py   # 商品向量模型 对应限界上下文的AI上下文 │       │   │   └── ai_session.py       # AI会话模型  
> │       │   ├── stores/          # AI数据存储（相当于AI的仓储层）  
> │       │   │   ├── product_vector_store.py   # 商品向量存储  
> │       │   │   ├── ai_session_store.py       # AI会话存储  
> │       │   │   └── knowledge_base.py         # 知识库  
> │       │   └── vector_store.py         # 向量数据库客户端
> ```

### 二、AI模块数据层实现
在编写代码前，需要明确数据层各组件的作用，和存在的必要性，并建立起它作为垂直领域组件的一个层级，与水平领域主项目类似层级的区别。
#### 2.1 AI应用所需的模型类
最简易实践：使用`chromadb`在内存中实现向量数据库存储：
```python
# 1. 加载文档  
loader = TextLoader("doc.md", encoding='utf-8')  
documents = loader.load()

# 2. 文本切分  
text_splitter = RecursiveCharacterTextSplitter(  
    chunk_size=100, # 每个文本块的大小  
    chunk_overlap=50    # 文本块之间的重叠部分  
)  
splits = text_splitter.split_documents(documents)

# 3. 向量化并存储
embedding_model = SentenceTransformer("Qwen/Qwen3-Embedding-0.6B")  
  
def embed_chunk(chunk: str) -> List[float]:  
    embedding = embedding_model.encode(chunk, normalize_embeddings=True)  
    return embedding.tolist()  
  
embeddings = [embed_chunk(chunk.page_content) for chunk in splits]

# 4. chromadb存储向量数据
import chromadb  
# EphemeralClient会创建一个内存型的向量数据库  
# 数据不会写入磁盘，脚本运行结束后就会自动清除数据  
# 如果需要写入磁盘则使用.PersistentClient("./chroma.db")  
# 该命令能够把数据存放在chroma.db这个文件中  
chromadb_client = chromadb.EphemeralClient()  
# collection是chromadb的概念，可类比于传统数据库中的表格  
chromadb_collection = chromadb_client.get_or_create_collection(name="default")  
  
def save_embeddings(chunks: List[str], embeddings: List[List[float]]) -> None:  
    for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):  
        chromadb_collection.add(  
            documents=[chunk],  
            embeddings=[embedding],  
            ids=[str(i)]  
        )  
chunks_text = [doc.page_content for doc in splits]  
save_embeddings(chunks_text, embeddings)

# 5. 召回阶段  
def retrieve(query: str, top_k: int) -> List[str]:  
    query_embedding = embed_chunk(query)  
    results = chromadb_collection.query(  
        query_embeddings=[query_embedding],  
        n_results=top_k  
    )  
    return results['documents'][0]  
  
query = "谁是奶龙？"  
retrieved_chunks = retrieve(query, 5)  
  
for i, chunk in enumerate(retrieved_chunks):  
    print(f"[{i}] {chunk}\n")
    
# 6. 重排部分，使用corss-encoder  
from sentence_transformers import CrossEncoder  
  
def rerank(query: str, retrieved_chunks: List[str], top_k: int) -> List[str]:  
    cross_encoder = CrossEncoder('cross-encoder/mmarco-mMiniLMv2-L12-H384-v1')  
    pairs = [(query, chunk) for chunk in retrieved_chunks]  
    scores = cross_encoder.predict(pairs)  
  
    scored_chunks = list(zip(retrieved_chunks, scores))  
    scored_chunks.sort(key=lambda x: x[1], reverse=True)  
    # print(scored_chunks)  
    return [chunk for chunk, _ in scored_chunks][:top_k]  
  
reranked_chunks = rerank(query, retrieved_chunks, 3)  
  
for i, chunk in enumerate(reranked_chunks):  
    print(f"[{i}] {chunk}\n")
```

> [!问题]
> **Q：** AI为什么需要模型类？它是支持ORM吗？上面的示例中是用chroma并使用内存存储的，它的流程就是准备好文档，切分好以后直接用embedding模型生成向量，就能够把它们配对好送进chroma了。这在更专业的PostgreSQL+pgvector中有什么变化吗？ 以及`product_vector.py`和`ai_session.py`都需要干什么？
> 
> **A：** 不是所有AI都需要模型类，而是企业级AI需要，但是它不是传统的ORM思维（前者过程导向，注重处理流程和向量表示；后者业务导向，注重实体和关系）在上面代码的第4部分通过`chroma_collection.add()`方法直接传入对应的chunk和嵌入向量，但是这种自由格式，无类型检查容易出错，并且难以支持负责的混合查询。而PostgreSQL + pgvector能够结合ORM支持企业级存储（插入ORM模型）、查询（混合查询）、更新（增量更新和版本控制）。`product_vector.py`中定义的就是这个插入的ORM模型，`ai_session.py`中定义的则是AI的会话ORM模型，管理AI对话的完整上下文。

#### 2.2 `core/datbase/base.py`定义`Base`基类
ORM数据模型需要通过继承`sqlalchemy`中的`Base`基类来实现，声明基类可以使用函数`sqlalchemy.orm.declarative_base()`实现，也可以通过继承`sqlalchemy.orm.DeclarativeBase`类实现，但是后一种方法可以在子类中编写约束规范。

> [!问题]
> **Q：** 在主项目中，原先`Base`基类存放在`model/__init__.py`中，同模块的其他实体继承它，并在文件最后导入。（因为当使用声明式基类时，**所有继承自`Base`基类的模型都会在`Base.metadata`中注册，但是这种注册只在模型类被导入时才会发生**，所以如果在另一个地方，如创建表时，只导入了`Base`而没有导入具体的模型类，那么`Base.metadata`中可能没有这些表，导致无法创建表。）**所以在文件末尾导入所有模型类可以确保程序在启动时，所有模型都被正确注册**。
> 以上是主项目的`Base`使用，但是AI模块也需要`Base`基类，而且如果这两个基类如果不相同，那么对于同一实体（比如商品）可能会造成元数据冲突，**所以`Base`基类需要统一**。**但是`Base`的定义应该放在哪里**？**又应该在哪里进行统一导入以便在模型迁移时能够正确地注册所有`Base`子类**？
> 
> **A：** 考虑到`Base`作为数据库相关基类且需要放在主项目和AI模块都能使用的地方，那么它应该存放在基础设施层`core/database`目录下，在`base.py`中定义。至于统一导入，这个功能是一次性的，可以单独放在`base.py`同级目录下，也可以放在其他`core`的非AI模块中，这里单独在一个模块`core/models/__init__.py`中统一导入，全模块只有这一个文件。所以`core`的目录结构再次调整为：
> ```text
> ├── core/                  # 核心层  
> │   ├── database/          # 数据库引擎  
> │   │   ├── base.py        # 定义ORM基类
> │   │   ├── engine.py      # 创建数据库引擎
> │   │   └── session.py     # 创建会话工厂和会话管理器
> │   ├── models/
> │   │   └── __init__.py    # 统一导入所有Base子类，保证alembic能完全迁移模型
> │   └── ai/                # AI核心（重构为清晰的层级）  
> │       ├── data/          # 数据层（是智能化的数据基础设施层） 
> │       ...
> ```
> 

另外，`core/datbase/base.py`中的基类定义为：
```python
"""  
此处（`core/database/base.py`）仅负责统一定义的 ORM Base 类，它将在两处使用：  
* 传统后端的`models/`定义业务数据实体  
* AI应用的`core/ai/data/models`定义向量模型和AI会话模型  
这两处定义的所有子类将在`core/models/__init__.py`集中导入，用作 alembic 模型迁移  
  
注：Base.metadata需要被`core/database/engine.py`中的引擎调用，用于创建表  
所以 Base 的所有子类都不应该再导入 `core/database/engine.py`内容，避免循环依赖  
"""  
from sqlalchemy import MetaData  
from sqlalchemy.orm import DeclarativeBase  
  
  
class Base(DeclarativeBase):  
    """  
    Base类是所有ORM Model类的父类。只有继承自Base类才够同步到数据库当中生成一张表  
    否则就要通过反射，让数据库中的数据映射到类  
    """    metadata = MetaData(naming_convention={  
        # ix: index，索引  
        "ix": "ix_%(column_0_label)s",  
        # un: unique，唯一约束  
        "uq": "uq_%(table_name)s_%(column_0_name)s",  
        # ck: Check，检查约束  
        "ck": "ck_%(table_name)s_%(constraint_name)s",  
        # fk: Foreign Key，外键约束  
        "fk": "fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s",  
        # pk: Primary Key，主键约束  
        "pk": "pk_%(table_name)s"  
    })  
  
  
__all__ = ["Base"]
```
#### 2.3 `core/ai/data/models/product_vector.py`定义ORM模型
`pgvector`是PostgreSQL的一个扩展功能，它能够让关系数据库PostgreSQL支持向量字段的存储和检索，这里定义一个ORM表示商品向量：
```python
class ProductVector(Base):  
    """商品向量 ORM 模型"""  
    __tablename__ = 'product_vector'  
  
    # 主键  
    id: Mapped[int] = mapped_column(
	    Integer, primary_key=True, autoincrement=True)  
  
    # 业务相关字段  
    product_id: Mapped[int] = mapped_column(
	    Integer, nullable=False, index=True, comment="原始商品ID")  
    title: Mapped[str] = mapped_column(
	    String(200), nullable=False, comment="商品标题")  
    description: Mapped[str] = mapped_column(
	    Text, nullable=False, comment="商品描述")  
  
    # 向量字段【需要改进：维度也应该能够在.env中进行设置】
    embedding: Mapped[List[float]] = mapped_column(
	    Vector(768), nullable=False, comment="向量数据")  
  
    # 时间戳  
    created_at: Mapped[datetime] = mapped_column(
	    DateTime, server_default=func.now())  
    updated_at: Mapped[datetime] = mapped_column(
	    DateTime, server_default=func.now(), onupdate=func.now())
```
#### 2.4 `core/ai/data/stores/product_vector_store.py`实现检索
检索功能由`core/ai/data/stores/product_vector_store.py`中`ProductVectorStore`来完成，它类似主应用的流程：配置数据库连接、会话工厂、构造会话依赖项后，定义ORM模型类，在服务层调用仓储层的功能，通过ORM操纵数据库数据。只是在AI模块中，操作数据库的方法又增加了一个向量检索。
但是在实现时有一个问题，`pgvector`是PostgreSQL的扩展字段，即使在alembic生成的`alembic/versions/xxxxxxxxx_init.py`中导入了`pgvector`，但是本地的PostgreSQL未经过`pgvector`扩展导致`init`脚本出现错误：
```text
HINT: The extension must first be installed on the system where PostgreSQL is running.
```
这就出现了两种解决方法：一个是本地配置（需要MSYS2环境，且配置较麻烦），另一个是使用Docker分离管控（企业级实践）。
【注：此处因为对于PostgreSQL的不熟悉，以及缺少Docker的项目实操，无法一次性解决该问题。所以把它做一个契机，沉下心来多花三四天去深入地理解并配合一些小实战，这段时间整理的笔记为】

Docker作为管理容器的工具，它通过内外端口映射来正确地把请求送给内部容器，并使用外部端口（宿主机的端口）作为容器的唯一标识，容器就像是宿主机上运行的一个软件。当网络请求（无论本机还是外部）到达，Docker会查看它内部的**端口绑定表**，根据请求中的端口号（如果有的话）找到对应的容器，再通过容器的端口映射规则，把外部端口（宿主机端口）映射到容器内部虚拟网络的端口号。而容器内部处理好请求后，再通过自己内网的端口发送给对方（请求方），中途再由Docker进行端口转换，双方就像在直接通信。**这种虚拟技术就像是计算机网络的VLAN和NAT，前者是数据链路层的隔离，后者是网络层的隔离**。**而Docker是一种操作系统级的虚拟化技术，它在应用层表现为一个独立的运行环境，但其网络部分的实现，深度融合了类似VLAN的隔离和类似NAT的转发机制（以太网交换机打上VLAN标签实现广播域的隔离<=>Docker通过给每个容器设置独立的网络栈实现彻底隔离；支持NAT的路由器通过IP映射实现内外网交互<=>Docker通过端口映射实现容器和外界通信）。**

考虑到适合企业级的实践，使用Docker来进行PostgreSQL的扩展，通过Docker的`run`指令从官方仓库`docker.io`（官方仓库所以可省略），作者名/命名空间为`ankane`（在GitHub上提交`pgvetor`的用户为`ankane`）的`pgvector`镜像，版本号为最新。
```bash
docker run -d \
  --name pg-vector \
  -e POSTGRES_PASSWORD=mysecretpassword \
  -e POSTGRES_DB=mydatabase \
  -p 55432:5432 \
  ankane/pgvector:latest
```
然后就创建了一个容器，它拉取了官方仓库的镜像，让名为`pg-vector`的容器有了一个外部端口为55432，对应内部端口为5432的端口映射。然后运行容器后，在pgAdmin4中创建端口为55432的新服务器，它就能够和容器内部的扩展了`vector`的PostgreSQL关联并操纵，并在新增扩展中能够添加`vetor`属性以支持向量存储了，扩展的细节记录在[[PostgreSQL和使用Docker完成pgvector扩展]]中。
所以在项目中的`settings/config.py`中，只需要把类`DatabaseSettings`中PostgreSQL对应的商品向量配置的端口属性改为55432（同样可以在`.env`中配置），导入了`pgvector`的`alembic`就能够正确地将模型迁移给数据库`backend_test`了。

> [!重要问题]
> **Q：** 目前的确完成了模型迁移，也开发好了向量数据库的增删改查功能，但是存在一个问题：向量数据库的地位在`一、技术选型`中已经确定为是**AI上下文，它是业务上下文的附属，它需要从传统业务的MySQL数据库中异步地写进PostgreSQL向量数据库**。理想情况下它应该只有主键、商品描述文本段、商品id、嵌入向量。而我设计的向量模型却定义了一些似乎冗余的字段：
> * `descrpition`商品描述字段通常文本量大，如果要同步可能需要大量时间和存储空间。
> * `created_at`和`updated_at`时间戳意义不明。
> 
> 考虑到`product_id`是不能省略，因为它是商品实体在AI和业务上下文的对接。那么既然`description`和`title`字段会带来同步负担和查询成本，是否可以在RAG需要输出描述时用`product_id`现查？但这似乎又影响了性能，**以高响应为目标的应用可能会更倾向用空间换时间。但是这又会导致AI上下文的喧宾夺主，它将会作为可独立使用的AI模块下的数据库，此时出现一个问题：如果在AI模块中对向量数据库数据增删改，这又会造成MySQL的商品数据的不一致**。
> 针对以上问题，我有一个想法：对于向量数据库的“仓储层”，**它应该仅向高层的知识库暴露查询操作**（这些都处于AI模块的数据层）。而**已经实现的增删改功能，则用于异步写入向量数据，相当于剥夺了AI模块能够修改数据的资格**。那么此时商品向量数据库完全依赖于商品业务数据库，那么`created_at`字段将无意义。所以流程就是：**不断地先调用传统数据库的查询操作，然后使用embedding模型处理，再调用AI模块的增删改查操作来正确地写入向量模型，同时监控传统数据库的改、删、增操作，保证两边数据库信息的同步**。那么`updated_at`字段也将意义不大，因为只要MySQL数据更新，新向量就会异步地写入PostgreSQL。【仅在后端不会出现任何问题的理想状况下成立】
> 但是这又存在一个问题：在[[优化：26-01-08 二维架构设计思想解决AI功能的融入问题]]中，我分析了最后AI的工具由服务层创建智能体时，将传统后端操作数据库的功能封装成工具传入。那么**这个异步确保数据一致性的功能应该运行在哪里**？**它又是否要遵循水平与垂直业务的隔离**？【注：在引用的这篇笔记中数据库操作由传统后端实现，并封装为工具，这同样也是DDD的防腐层思想】
>
>**A：** ① RAG在检索时不仅需要向量相似度，经常还需要直接访问原文片段进行精准提示或展示。如果每次都通过 `product_id` 回查业务数据库，会产生**跨数据库的网络IO**，这在高性能场景下是不可接受的。在向量侧存储关键文本是通用做法，所以`description`字段和`title`字段应该保留。
>另外`created_at`仅在简单场景下能被`updated_at`替换，但**在企业级项目中二者缺一不可**：`updated_at`是同步的“信号源”，向量数据库可以通过这个字段确保数据最终一致，并且可以用于监控和调试（判断同步延迟、定位同步失败的数据批次）。而`created_at`标记了向量数据的首次创建时间，可用于数据溯源和生命周期管理。
>考虑一个情景：用户报告AI推荐商品描述与实际不符，如果只有`updated_at`那么只知道数据在那时更新过，但是却不知道它是什么时候创建的。这导致排查只能盲目地重新同步所有数据，或花大量时间人工比对日志。
>② **AI模块的职责是消费和使用数据**，而数据的权威来源应该是核心的业务系统（水平领域）。禁止AI模块直接修改向量，是从架构上杜绝了数据混乱的可能。这体现了清晰的 **“分层”与“防腐”** 思想。而这样一个负责同步的组件，既不属于纯粹的传统业务域，也不属于AI域，它是DDD领域防腐层的一个具体实现。


### 三、优化：使用LangChain内置工具替代


