## 总结



## 学习过程
### 一、技术选型
根据B站的向量数据库测评总结以及AI分析得到的整理文档[[向量库技术对比]]，再结合初步打算实现的功能：**商品推荐和商品知识库**。考虑分别针对两个功能选择不同类型的向量数据库：
* 使用faiss+Redis存储**用户行为向量**；
* 使用PostgreSQL + pgvector实现**商品数据的向量保存**；
* 使用qdrant实现**知识库检索**。
**Q：** 在[[优化：26-01-07 模块解耦思想在仓储层中的应用]]和[[优化：26-01-08 二维架构设计思想解决AI功能的融入问题]]两篇记录中，我总结出来的数据/仓储层的设计是：
* MySQL存储用户、商品、订单等信息；
* PostgreSQL存储智能体上下文消息；
* Redis存储高频的非关键信息
* 向量数据库选择暂定
* 并且把和AI相关的数据库：向量数据库和负责会话存储的PostgreSQL放入`core/ai/data`目录中
但是上面的推荐技术选型中，”使用PostgreSQL + pgvector实现商品数据的保存“，与我目前的MySQL数据库存储商品实现了冲突。**我希望商品知识库的功能能够企业级规范地实践，但是目前的设计出现了同一数据库（PostgreSQL）将要分别实现水平领域和垂直领域功能的需求；并且从另一角度看，商品实体要同时实现传统后端事务处理（保持原样）和向量检索（改变数据库使用向量存储），应该如何协调以平衡这个矛盾，并且避免代码大量重复**？我的想法是使用单例依赖项分别注入到AI模块实现会话存取，以及后端仓储模块实现商品存取中，它们存取的数据类型不同，所以可能并没有多少代码重复。但是如果单是商品使用了PostgreSQL，又会不会让主应用的数据库不够同一，**需不需要把其他数据统一转移到PostgreSQL**？另外**如果是在已经部署的生产环境下，MySQL数据库已经存在大量的数据了**，即使完成了商品部分的转移以更好地实现RAG功能，**那对于其他字段的安排又有什么更专业的做法，是全部迁移还是仅迁移冲突数据**？
**A：** 这种冲突情况不推荐数据的全部迁移，甚至不推荐把冲突字段（商品）彻底迁移，因为MySQL在事务处理上非常成熟，全部迁移不合适，把冲突的几个表迁移也不太合适，因为那会导致传统后端业务的不方便。在生产环境下（已经存储了大量业务数据时），更成熟的做法是：**领域驱动设计（DDD）的限界上下文**【注：DDD的思想在[[优化：26-01-08 二维架构设计思想解决AI功能的融入问题]]中也有体现】，**即同一实体在不同上下文可以有不同的表示，一个商品实体可以在传统后端业务中有交易上下文（MySQL），在AI模块中有AI上下文（PostgreSQL + pgvector）**。
简单来说就是：**不迁移，而是保留MySQL的冲突数据（商品，将其作为权威数据源）**，让完整的事务数据还是由MySQL统一管控。但是对于冲突的解决，则是**另外开一个PostgreSQL + pgvector，作为实现冲突数据的”附加属性“，实现双存储。这就像是向量数据是MySQL冲突实体的一个向量形式的知识挂件（衍生数据视图）**。它只在AI需要的时候单独从PostgreSQL调用。此外，这两个需要同步，所以有一些策略保证在持续运行的情况下能异步地向PostgreSQL更新已存在的商品知识。
**这种异构数据库架构的做法体现了数据网格的思想（把数据按职责划分给不同团队管控，让MySQL负责交易数据，让PostgreSQL负责向量知识存储），保证MySQL管钱、PostgreSQL+pgvector管知识、Redis管速度。**
结合这样的思想，将项目的`ai`模块的单个数据文件整合为为一个数据层模块：
```text
│   └── ai/                   # AI核心（重构为清晰的层级）  
│       ├── data/             # ⭐数据层（是智能化的数据基础设施层）  
│       │   ├── models/          # 是AI功能需要的模型 
│       │   │   ├── product_vector.py   # 商品向量模型 对应限界上下文的AI上下文 │       │   │   └── ai_session.py       # AI会话模型  
│       │   ├── stores/          # AI数据存储（相当于AI的仓储层）  
│       │   │   ├── product_vector_store.py   # 商品向量存储  
│       │   │   ├── ai_session_store.py       # AI会话存储  
│       │   │   └── knowledge_base.py         # 知识库  
│       │   └── vector_store.py         # 向量数据库客户端
```

### 二、AI模块数据层实现
在编写代码前，需要明确数据层各组件的作用，和存在的必要性，并建立起它作为垂直领域组件的一个层级，与水平领域主项目类似层级的区别。
#### 2.1 AI应用所需的模型类
**Q：** AI为什么需要模型类？它是支持ORM吗？我在之前的实践中是用chroma并使用内存存储的，它的流程就是准备好文档，切分好以后直接用embedding模型生成向量，就能够把它们配对好送进chroma了：
```python
# 1. 加载文档  
loader = TextLoader("doc.md", encoding='utf-8')  
documents = loader.load()

# 2. 文本切分  
text_splitter = RecursiveCharacterTextSplitter(  
    chunk_size=100, # 每个文本块的大小  
    chunk_overlap=50    # 文本块之间的重叠部分  
)  
splits = text_splitter.split_documents(documents)

# 3. 向量化并存储
embedding_model = SentenceTransformer("Qwen/Qwen3-Embedding-0.6B")  
  
def embed_chunk(chunk: str) -> List[float]:  
    embedding = embedding_model.encode(chunk, normalize_embeddings=True)  
    return embedding.tolist()  
  
embeddings = [embed_chunk(chunk.page_content) for chunk in splits]

# 4. chromadb存储向量数据
import chromadb  
# EphemeralClient会创建一个内存型的向量数据库  
# 数据不会写入磁盘，脚本运行结束后就会自动清除数据  
# 如果需要写入磁盘则使用.PersistentClient("./chroma.db")  
# 该命令能够把数据存放在chroma.db这个文件中  
chromadb_client = chromadb.EphemeralClient()  
# collection是chromadb的概念，可类比于传统数据库中的表格  
chromadb_collection = chromadb_client.get_or_create_collection(name="default")  
  
def save_embeddings(chunks: List[str], embeddings: List[List[float]]) -> None:  
    for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):  
        chromadb_collection.add(  
            documents=[chunk],  
            embeddings=[embedding],  
            ids=[str(i)]  
        )  
chunks_text = [doc.page_content for doc in splits]  
save_embeddings(chunks_text, embeddings)

# 5. 召回阶段  
def retrieve(query: str, top_k: int) -> List[str]:  
    query_embedding = embed_chunk(query)  
    results = chromadb_collection.query(  
        query_embeddings=[query_embedding],  
        n_results=top_k  
    )  
    return results['documents'][0]  
  
query = "谁是奶龙？"  
retrieved_chunks = retrieve(query, 5)  
  
for i, chunk in enumerate(retrieved_chunks):  
    print(f"[{i}] {chunk}\n")
    
# 6. 重排部分，使用corss-encoder  
from sentence_transformers import CrossEncoder  
  
def rerank(query: str, retrieved_chunks: List[str], top_k: int) -> List[str]:  
    cross_encoder = CrossEncoder('cross-encoder/mmarco-mMiniLMv2-L12-H384-v1')  
    pairs = [(query, chunk) for chunk in retrieved_chunks]  
    scores = cross_encoder.predict(pairs)  
  
    scored_chunks = list(zip(retrieved_chunks, scores))  
    scored_chunks.sort(key=lambda x: x[1], reverse=True)  
    # print(scored_chunks)  
    return [chunk for chunk, _ in scored_chunks][:top_k]  
  
reranked_chunks = rerank(query, retrieved_chunks, 3)  
  
for i, chunk in enumerate(reranked_chunks):  
    print(f"[{i}] {chunk}\n")
```
这在更专业的PostgreSQL+pgvector中有什么变化吗？ 以及`product_vector.py`和`ai_session.py`都需要干什么？
**A：** 不是所有AI都需要模型类，而是企业级AI需要，但是它不是传统的ORM思维（前者过程导向，注重处理流程和向量表示；后者业务导向，注重实体和关系）在上面代码的第4部分通过`chroma_collection.add()`方法直接传入对应的chunk和嵌入向量，但是这种自由格式，无类型检查容易出错，并且难以支持负责的混合查询。而PostgreSQL + pgvector能够结合ORM支持企业级存储（插入ORM模型）、查询（混合查询）、更新（增量更新和版本控制）。`product_vector.py`中定义的就是这个插入的ORM模型，`ai_session.py`中定义的则是AI的会话ORM模型，管理AI对话的完整上下文。
#### 2.2 `core/datbase/base.py`定义`Base`基类
ORM数据模型需要通过继承`sqlalchemy`中的`Base`基类来实现，声明基类可以使用函数`sqlalchemy.orm.declarative_base()`实现，也可以通过继承`sqlalchemy.orm.DeclarativeBase`类实现，但是后一种方法可以在子类中编写约束规范。
**Q：** 在主项目中，原先`Base`基类存放在`model/__init__.py`中，同模块的其他实体继承它，并在文件最后导入。（因为当使用声明式基类时，**所有继承自`Base`基类的模型都会在`Base.metadata`中注册，但是这种注册只在模型类被导入时才会发生**，所以如果在另一个地方，如创建表时，只导入了`Base`而没有导入具体的模型类，那么`Base.metadata`中可能没有这些表，导致无法创建表。）**所以在文件末尾导入所有模型类可以确保程序在启动时，所有模型都被正确注册**。
以上是主项目的`Base`使用，但是AI模块也需要`Base`基类，而且如果这两个基类如果不相同，那么对于同一实体（比如商品）可能会造成元数据冲突，**所以`Base`基类需要统一**。**但是`Base`的定义应该放在哪里**？**又应该在哪里进行统一导入以便在模型迁移时能够正确地注册所有`Base`子类**？
**A：** 考虑到`Base`作为数据库相关基类且需要放在主项目和AI模块都能使用的地方，那么它应该存放在基础设施层`core/database`目录下，在`base.py`中定义。至于统一导入，这个功能是一次性的，可以单独放在`base.py`同级目录下，也可以放在其他`core`的非AI模块中，这里单独在一个模块`core/models/__init__.py`中统一导入，全模块只有这一个文件。所以`core`的目录结构再次调整为：
```text
├── core/                  # 核心层  
│   ├── database/          # 数据库引擎  
│   │   ├── base.py        # 定义ORM基类
│   │   ├── engine.py      # 创建数据库引擎
│   │   └── session.py     # 创建会话工厂和会话管理器
│   ├── models/
│   │   └── __init__.py    # 统一导入所有Base子类，保证alembic能完全迁移模型
│   └── ai/                # AI核心（重构为清晰的层级）  
│       ├── data/          # 数据层（是智能化的数据基础设施层） 
│       ...
```
另外，`core/datbase/base.py`中的基类定义为：
```python
"""  
此处（`core/database/base.py`）仅负责统一定义的 ORM Base 类，它将在两处使用：  
* 传统后端的`models/`定义业务数据实体  
* AI应用的`core/ai/data/models`定义向量模型和AI会话模型  
这两处定义的所有子类将在`core/models/__init__.py`集中导入，用作 alembic 模型迁移  
  
注：Base.metadata需要被`core/database/engine.py`中的引擎调用，用于创建表  
所以 Base 的所有子类都不应该再导入 `core/database/engine.py`内容，避免循环依赖  
"""  
from sqlalchemy import MetaData  
from sqlalchemy.orm import DeclarativeBase  
  
  
class Base(DeclarativeBase):  
    """  
    Base类是所有ORM Model类的父类。只有继承自Base类才够同步到数据库当中生成一张表  
    否则就要通过反射，让数据库中的数据映射到类  
    """    metadata = MetaData(naming_convention={  
        # ix: index，索引  
        "ix": "ix_%(column_0_label)s",  
        # un: unique，唯一约束  
        "uq": "uq_%(table_name)s_%(column_0_name)s",  
        # ck: Check，检查约束  
        "ck": "ck_%(table_name)s_%(constraint_name)s",  
        # fk: Foreign Key，外键约束  
        "fk": "fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s",  
        # pk: Primary Key，主键约束  
        "pk": "pk_%(table_name)s"  
    })  
  
  
__all__ = ["Base"]
```
#### 2.3 `core/ai/data/models/product_vector.py`定义ORM模型
`pgvector`是PostgreSQL的一个扩展功能，它能够让关系数据库PostgreSQL支持向量字段的存储和检索，这里定义一个ORM表示商品向量：
```python
class ProductVector(Base):  
    """商品向量 ORM 模型"""  
    __tablename__ = 'product_vector'  
  
    # 主键  
    id: Mapped[int] = mapped_column(
	    Integer, primary_key=True, autoincrement=True)  
  
    # 业务相关字段  
    product_id: Mapped[int] = mapped_column(
	    Integer, nullable=False, index=True, comment="原始商品ID")  
    title: Mapped[str] = mapped_column(
	    String(200), nullable=False, comment="商品标题")  
    description: Mapped[str] = mapped_column(
	    Text, nullable=False, comment="商品描述")  
  
    # 向量字段  
    embedding: Mapped[List[float]] = mapped_column(
	    Vector(768), nullable=False, comment="向量数据")  
  
    # 时间戳  
    created_at: Mapped[datetime] = mapped_column(
	    DateTime, server_default=func.now())  
    updated_at: Mapped[datetime] = mapped_column(
	    DateTime, server_default=func.now(), onupdate=func.now())
```
#### 2.4 `core/ai/data/stores/product_vector_store.py`实现检索
检索功能由`core/ai/data/stores/product_vector_store.py`中`ProductVectorStore`来完成，它类似主应用的流程：配置数据库连接、会话工厂、构造会话依赖项后，定义ORM模型类，在服务层调用仓储层的功能，通过ORM操纵数据库数据。只是在AI模块中，操作数据库的方法又增加了一个向量检索。
但是在实现时有一个问题，`pgvector`是PostgreSQL的扩展字段，即使在alembic生成的`alembic/versions/xxxxxxxxx_init.py`中导入了`pgvector`，但是本地的PostgreSQL未经过`pgvector`扩展导致`init`脚本出现错误：
```text
HINT: The extension must first be installed on the system where PostgreSQL is running.
```
这就出现了两种解决方法：一个是本地配置（需要MSYS2环境，且配置较麻烦），另一个是使用Docker分离管控（企业级实践）。
【注：此处因为我对于PostgreSQL的不熟悉，以及缺少Docker的项目实操，无法一次性解决该问题。所以把它做一个契机，沉下心来多花三四天去深入地理解并配合一些小实战，这段时间整理的笔记为[[PostgreSQL和pgvector]]（01-15）】

